{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.9-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting typedict\n",
      "  Downloading typedict-0.1.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.8-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: ipython in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (9.10.0)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.2.11 (from langchain-openai)\n",
      "  Downloading langchain_core-1.2.11-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai)\n",
      "  Downloading openai-2.20.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Using cached tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Downloading langsmith-0.7.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.11->langchain-openai) (26.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Downloading tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Downloading uuid_utils-0.14.0-cp39-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic)\n",
      "  Using cached pydantic_core-2.41.5-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Downloading orjson-3.11.7-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash>=3.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached zstandard-0.25.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
      "  Downloading jiter-0.13.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
      "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2026.1.15-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.3.5-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.12.2-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from jedi>=0.18.1->ipython) (0.8.6)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.11->langchain-openai)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from stack_data>=0.6.0->ipython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from stack_data>=0.6.0->ipython) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\gitprojects\\mses10\\venv\\lib\\site-packages (from stack_data>=0.6.0->ipython) (0.2.3)\n",
      "Downloading langchain_openai-1.1.9-py3-none-any.whl (85 kB)\n",
      "Downloading langchain_core-1.2.11-py3-none-any.whl (500 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.7.1-py3-none-any.whl (322 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading openai-2.20.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 9.2 MB/s  0:00:00\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.13.0-cp313-cp313-win_amd64.whl (202 kB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Downloading tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading uuid_utils-0.14.0-cp39-abi3-win_amd64.whl (182 kB)\n",
      "Downloading typedict-0.1.0-py3-none-any.whl (6.6 kB)\n",
      "Downloading langgraph-1.0.8-py3-none-any.whl (158 kB)\n",
      "Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.3.5-py3-none-any.whl (70 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.7-cp313-cp313-win_amd64.whl (124 kB)\n",
      "Downloading ormsgpack-1.12.2-cp313-cp313-win_amd64.whl (117 kB)\n",
      "Downloading regex-2026.1.15-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Using cached zstandard-0.25.0-cp313-cp313-win_amd64.whl (506 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, xxhash, uuid-utils, urllib3, typing-extensions, typedict, tqdm, tenacity, sniffio, regex, pyyaml, python-dotenv, ormsgpack, orjson, jsonpointer, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, pydantic, httpx, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph\n",
      "\n",
      "   --- ------------------------------------  3/40 [urllib3]\n",
      "   --- ------------------------------------  3/40 [urllib3]\n",
      "   ------ ---------------------------------  6/40 [tqdm]\n",
      "   ------ ---------------------------------  6/40 [tqdm]\n",
      "   --------- ------------------------------  9/40 [regex]\n",
      "   ---------- ----------------------------- 10/40 [pyyaml]\n",
      "   ----------- ---------------------------- 11/40 [python-dotenv]\n",
      "   ---------------- ----------------------- 16/40 [idna]\n",
      "   ------------------ --------------------- 18/40 [distro]\n",
      "   ------------------- -------------------- 19/40 [charset_normalizer]\n",
      "   ----------------------- ---------------- 23/40 [requests]\n",
      "   ------------------------- -------------- 25/40 [jsonpatch]\n",
      "   -------------------------- ------------- 26/40 [httpcore]\n",
      "   --------------------------- ------------ 27/40 [anyio]\n",
      "   ---------------------------- ----------- 28/40 [tiktoken]\n",
      "   ----------------------------- ---------- 29/40 [requests-toolbelt]\n",
      "   ------------------------------ --------- 30/40 [pydantic]\n",
      "   ------------------------------ --------- 30/40 [pydantic]\n",
      "   ------------------------------ --------- 30/40 [pydantic]\n",
      "   ------------------------------ --------- 30/40 [pydantic]\n",
      "   ------------------------------ --------- 30/40 [pydantic]\n",
      "   ------------------------------- -------- 31/40 [httpx]\n",
      "   ------------------------------- -------- 31/40 [httpx]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   -------------------------------- ------- 32/40 [openai]\n",
      "   --------------------------------- ------ 33/40 [langsmith]\n",
      "   --------------------------------- ------ 33/40 [langsmith]\n",
      "   --------------------------------- ------ 33/40 [langsmith]\n",
      "   --------------------------------- ------ 33/40 [langsmith]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ----------------------------------- ---- 35/40 [langchain-core]\n",
      "   ------------------------------------- -- 37/40 [langchain-openai]\n",
      "   -------------------------------------- - 38/40 [langgraph-prebuilt]\n",
      "   ---------------------------------------  39/40 [langgraph]\n",
      "   ---------------------------------------  39/40 [langgraph]\n",
      "   ---------------------------------------  39/40 [langgraph]\n",
      "   ---------------------------------------- 40/40 [langgraph]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.1 certifi-2026.1.4 charset_normalizer-3.4.4 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.13.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-1.2.11 langchain-openai-1.1.9 langgraph-1.0.8 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.7 langgraph-sdk-0.3.5 langsmith-0.7.1 openai-2.20.0 orjson-3.11.7 ormsgpack-1.12.2 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 pyyaml-6.0.3 regex-2026.1.15 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.4 tiktoken-0.12.0 tqdm-4.67.3 typedict-0.1.0 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.3 uuid-utils-0.14.0 xxhash-3.6.0 zstandard-0.25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai langchain_ollama pydantic typeddict langgraph ipython python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f610f",
   "metadata": {},
   "source": [
    "### Equipo publicitario para Cafe.AI ‚òïüòé\n",
    "A continuaci√≥n, considere el lanzamiento de un nuevo cafe en su barrio llamado Cafe.AI ‚òï\n",
    "Caf√© donde la tecnolog√≠a y el sabor convergen, tu espacio para conectar, crear e innovar, una taza a la vez. Dise√±ado como un caf√© inteligente para mentes creativas, con conexi√≥n r√°pida, caf√© excepcional y un ambiente pensado para que tus mejores ideas florezcan. Aqu√≠, caf√© m√°s IA equivale a tu nuevo espacio de trabajo donde la creatividad se sirve con crema. Un lugar destinado a innovadores, desarrolladores y so√±adores que entienden que la mejor idea surge en una buena conversaci√≥n, con datos, di√°logos y el caf√© m√°s inteligente de la ciudad en la misma mesa.\n",
    "\n",
    "En base al c√≥digo revisado en clase, proponga un equipo publicitario encargado de su primera campa√±a publicitaria para redes sociales. Dicho equipo debe contar con un enrutador, un rol creativo, uno redactor y un dise√±ador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e110361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama # Establece la conexi√≥n con el modelo de lenguaje de Ollama\n",
    "llm = ChatOllama(model=\"llama3.2:latest\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f397c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† El equipo publicitario est√° trabajando en tu campa√±a...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# üöÄ Propuesta de Campa√±a: Cafe.AI\n",
       "---\n",
       "## üí° Concepto Creativo (Director Creativo)\n",
       "**Concepto de Campa√±a Disruptiva: \"Cafe.AI: El Laboratorio de la Innovaci√≥n\"**\n",
       "\n",
       "Nuestra campa√±a disruptiva busca posicionar a Cafe.AI como el lugar perfecto para programadores y innovadores que buscan inspiraci√≥n y energ√≠a para crear algo nuevo. La idea es crear un ambiente que combine la tecnolog√≠a con la creatividad, donde los visitantes puedan experimentar la fusi√≥n de la innovaci√≥n y el sabor. Para lograr esto, dise√±aremos una experiencia inmersiva que incluya estaciones de trabajo optimizadas, eventos de hackathon y talleres de desarrollo de software, todo rodeado de una atm√≥sfera moderna y acogedora.\n",
       "\n",
       "La campa√±a se llamar√° \"Descubre tu c√≥digo\" y se centrar√° en la idea de que Cafe.AI es el lugar donde la tecnolog√≠a y el sabor convergen para crear algo nuevo. Utilizaremos medios digitales, redes sociales y publicidad en l√≠nea para llegar a nuestro p√∫blico objetivo, y tambi√©n contaremos con una estrategia de influencer para promocionar la marca y atraer a nuevos clientes. Nuestro objetivo es convertir a Cafe.AI en el lugar m√°s popular entre programadores e innovadores, donde puedan encontrar inspiraci√≥n y energ√≠a para crear algo nuevo y revolucionario.\n",
       "\n",
       "---\n",
       "## ‚úçÔ∏è Redacci√≥n de Contenidos (Copywriter)\n",
       "**Post para Instagram:**\n",
       "\n",
       "¬°Descubre tu c√≥digo!\n",
       "\n",
       "¬øEst√°s listo para fusionar la tecnolog√≠a con el sabor? ¬°Bienvenido a Cafe.AI, el laboratorio de la innovaci√≥n! \n",
       "\n",
       "En nuestro espacio inmersivo, la creatividad y la energ√≠a se unen para inspirarte a crear algo nuevo. Experimenta nuestras estaciones de trabajo optimizadas, asiste a eventos de hackathon y talleres de desarrollo de software.\n",
       "\n",
       "¬°√önete a nuestra comunidad de programadores e innovadores que buscan cambiar el mundo! \n",
       "\n",
       "#CafeAI #DescubreTuC√≥digo #LaboratorioDeLaInnovaci√≥n #TechMeetsFood #Innovaci√≥nEnAcci√≥n #Programaci√≥nYSabor #Energ√≠aParaCrear\n",
       "\n",
       "**Mensaje corto para LinkedIn:**\n",
       "\n",
       "\"¬øEst√°s listo para fusionar la tecnolog√≠a con el sabor? Cafe.AI es el lugar perfecto para programadores e innovadores que buscan inspiraci√≥n y energ√≠a para crear algo nuevo. ¬°√önete a nuestra comunidad de creativos y emprendedores que est√°n cambiando el mundo! #CafeAI #DescubreTuC√≥digo #Innovaci√≥nEnAcci√≥n\"\n",
       "\n",
       "Recuerda personalizar los hashtags seg√∫n tus necesidades espec√≠ficas y ajustar el tono y el estilo para adaptarse a tu audiencia objetivo. ¬°Buena suerte con tu campa√±a disruptiva!\n",
       "\n",
       "---\n",
       "## üé® Direcci√≥n de Arte y Visuales (Dise√±ador)\n",
       "**Est√©tica Visual:**\n",
       "\n",
       "La est√©tica visual de la campa√±a se centra en crear un ambiente futurista y minimalista que refleje la fusi√≥n de la tecnolog√≠a y el sabor. Los colores primarios son:\n",
       "\n",
       "* Azul claro (#87CEEB) para representar la innovaci√≥n y la creatividad\n",
       "* Blanco (#FFFFFF) para simbolizar la limpieza y la claridad mental\n",
       "* Gris oscuro (#333333) para agregar un toque de sofisticaci√≥n y madurez\n",
       "\n",
       "La iluminaci√≥n es suave y c√°lida, con un tono azul claro que evoca una sensaci√≥n de inspiraci√≥n y energ√≠a. Los elementos de c√≥digo y caf√© de especialidad se presentan de manera minimalista y elegante, con l√≠neas limpias y formas geom√©tricas precisas.\n",
       "\n",
       "**Prompts para DALL-E/Midjourney:**\n",
       "\n",
       "1. **\"Un laboratorio de innovaci√≥n futurista con estaciones de trabajo optimizadas y eventos de hackathon en un entorno de caf√© de especialidad. La iluminaci√≥n es suave y c√°lida, con un tono azul claro que evoca una sensaci√≥n de inspiraci√≥n y energ√≠a.\"**\n",
       "\n",
       "2. **\"Un logo minimalista para Cafe.AI con elementos de c√≥digo y caf√© de especialidad. El dise√±o debe reflejar la fusi√≥n de la tecnolog√≠a y el sabor, con l√≠neas limpias y formas geom√©tricas precisas en un fondo azul claro (#87CEEB). La tipograf√≠a debe ser moderna y futurista, con una fuente sans-serif que transmita energ√≠a y creatividad.\"**\n",
       "\n",
       "Estos prompts buscan capturar la esencia de la campa√±a y crear im√°genes visuales que inspiren a los usuarios a fusionar la tecnolog√≠a con el sabor. La combinaci√≥n de colores, iluminaci√≥n y elementos de c√≥digo y caf√© de especialidad debe transmitir una sensaci√≥n de innovaci√≥n, creatividad y energ√≠a.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 1. Configuraci√≥n del Modelo (Ollama local en el Codespace)\n",
    "# Usamos base_url para asegurar que apunte al servicio que acabas de levantar\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:latest\", \n",
    "    temperature=0.3,\n",
    "    num_predict=1024\n",
    ")\n",
    "\n",
    "# 2. Definici√≥n del Estado (La memoria compartida del equipo)\n",
    "class State(TypedDict):\n",
    "    input: str            # El brief de Cafe.AI\n",
    "    concepto: str         # Idea del Creativo\n",
    "    copy: str             # Textos del Redactor\n",
    "    diseno: str           # Visuales del Dise√±ador\n",
    "\n",
    "# 3. Nodos del Equipo Publicitario\n",
    "\n",
    "def nodo_creativo(state: State):\n",
    "    \"\"\"Rol: Director Creativo\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Eres el Director Creativo de Cafe.AI. \n",
    "    Brief: {state['input']}\n",
    "    Tarea: Crea un concepto de campa√±a disruptivo que posicione el caf√© como el combustible para programadores e innovadores.\n",
    "    Respuesta: Solo el concepto creativo en 2 p√°rrafos.\n",
    "    \"\"\"\n",
    "    res = llm.invoke(prompt)\n",
    "    return {\"concepto\": res.content}\n",
    "\n",
    "def nodo_redactor(state: State):\n",
    "    \"\"\"Rol: Senior Copywriter\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Eres Copywriter Senior. Basado en el concepto: {state['concepto']}\n",
    "    Tarea: Escribe un post atractivo para Instagram (incluye hashtags) y un mensaje corto para LinkedIn.\n",
    "    Estilo: Inteligente, tech y energ√©tico.\n",
    "    \"\"\"\n",
    "    res = llm.invoke(prompt)\n",
    "    return {\"copy\": res.content}\n",
    "\n",
    "def nodo_disenador(state: State):\n",
    "    \"\"\"Rol: Director de Arte / Prompt Engineer\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Eres Director de Arte. Basado en el copy: {state['copy']}\n",
    "    Tarea: Describe la est√©tica visual de la campa√±a (colores, iluminaci√≥n) y genera 2 prompts detallados para DALL-E/Midjourney.\n",
    "    Estilo: Futurista, minimalista, con elementos de c√≥digo y caf√© de especialidad.\n",
    "    \"\"\"\n",
    "    res = llm.invoke(prompt)\n",
    "    return {\"diseno\": res.content}\n",
    "\n",
    "# 4. Construcci√≥n del Grafo (LangGraph)\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"creativo\", nodo_creativo)\n",
    "builder.add_node(\"redactor\", nodo_redactor)\n",
    "builder.add_node(\"disenador\", nodo_disenador)\n",
    "\n",
    "builder.add_edge(START, \"creativo\")\n",
    "builder.add_edge(\"creativo\", \"redactor\")\n",
    "builder.add_edge(\"redactor\", \"disenador\")\n",
    "builder.add_edge(\"disenador\", END)\n",
    "\n",
    "# Compilamos el equipo\n",
    "equipo_publicitario = builder.compile()\n",
    "\n",
    "# 5. Ejecuci√≥n de la Campa√±a\n",
    "brief_lanzamiento = \"\"\"\n",
    "Cafe.AI ‚òï: Un caf√© inteligente en el coraz√≥n de la ciudad. \n",
    "Ofrecemos caf√© de especialidad y estaciones de trabajo optimizadas para mentes creativas. \n",
    "Slogan: \"Donde la tecnolog√≠a y el sabor convergen\".\n",
    "\"\"\"\n",
    "\n",
    "print(\"üß† El equipo publicitario est√° trabajando en tu campa√±a...\")\n",
    "\n",
    "try:\n",
    "    resultado = equipo_publicitario.invoke({\"input\": brief_lanzamiento})\n",
    "\n",
    "    # Mostrar resultados finales\n",
    "    display(Markdown(f\"\"\"\n",
    "# üöÄ Propuesta de Campa√±a: Cafe.AI\n",
    "---\n",
    "## üí° Concepto Creativo (Director Creativo)\n",
    "{resultado['concepto']}\n",
    "\n",
    "---\n",
    "## ‚úçÔ∏è Redacci√≥n de Contenidos (Copywriter)\n",
    "{resultado['copy']}\n",
    "\n",
    "---\n",
    "## üé® Direcci√≥n de Arte y Visuales (Dise√±ador)\n",
    "{resultado['diseno']}\n",
    "\"\"\"))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar con Ollama: {e}\")\n",
    "    print(\"Verifica que corriste 'ollama serve &' y 'ollama pull llama3.2:latest' en la terminal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c716f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
